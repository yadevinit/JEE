{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cVM <- \"Azure\" # cloud service. Alt: \"Sony\" local laptop.\ncWorkDir <- switch(cVM,\n  Azure = \".\",\n  \"C:\\\\Users\\\\SONY\\\\Documents/../Desktop/preBachelors/www/solnJEEAdvanced\" # by default\n)\ncYPtill <- \"Y2018P2\"",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ref https://github.com/wesslen/topicApp\npackages1 <- c(\"quanteda\",\"RColorBrewer\",\"visNetwork\",\"ggwordcloud\",\n               \"igraph\",\"tm\",\"reshape\",\"tidyverse\",\"stm\")\npackages <- c(\"shiny\",\"quanteda\",\"shinydashboard\",\"RColorBrewer\",\"DT\",\"visNetwork\",\"ggwordcloud\",\n               \"igraph\",\"tm\",\"reshape\",\"grid\",\"tidyverse\",\"shinyjs\",\"shinyBS\",\"stm\")\npackages2 <- setdiff(packages, packages1)\n  install.packages(packages1)\nif(FALSE){ # Run if packages have not been installed.\n  install.packages(packages2)\n  install.packages(\"devtools\")\n  install.packages(\"pdftools\")\n  install.packages(\"tesseract\")\n  devtools::install_github(\"wesslen/topicApp\")\n  # devtools::install_github(\"trinker/textreadr\")\n} # else continue\n\nfor(pkg in packages1){\n  library(pkg, character.only=TRUE)\n  # \"tm\" attaches \"NLP\". annotate is masked from package:ggplot2.\n  # {as.DocumentTermMatrix, stopwords} are masked from package:quanteda.\n}\n# for(pkg in packages2){\n#     library(pkg, character.only=TRUE)\n# }\n# library(pdftools)\n# library(tesseract)\n# library(topicApp)\n# library(textreadr)\n",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Installing packages into ‘/home/nbuser/R’\n(as ‘lib’ is unspecified)\nalso installing the dependencies ‘haven’, ‘modelr’\n\nWarning message in install.packages(packages1):\n“installation of package ‘quanteda’ had non-zero exit status”Warning message in install.packages(packages1):\n“installation of package ‘tm’ had non-zero exit status”Warning message in install.packages(packages1):\n“installation of package ‘tidyverse’ had non-zero exit status”Warning message:\n“S3 methods ‘$.corpus’, ‘$.dfm’, ‘$.dictionary2’, ‘$.fcm’, ‘$.tokens’, ‘$<-.corpus’, ‘$<-.dfm’, ‘$<-.fcm’, ‘$<-.tokens’, ‘+.corpus’, ‘+.tokens’, ‘[.corpus’, ‘[.kwic’, ‘[.summary.corpus’, ‘[.textstat’, ‘[.tokens’, ‘[<-.tokens’, ‘[[.dfm’, ‘[[.tokens’, ‘[[<-.tokens’, ‘docnames<-.corpus’, ‘docnames<-.default’, ‘docnames<-.dfm’, ‘docnames<-.tokens’, ‘docvars<-.corpus’, ‘docvars<-.default’, ‘docvars<-.dfm’, ‘docvars<-.tokens’, ‘meta<-.corpus’, ‘meta<-.dfm’, ‘meta<-.dictionary2’, ‘meta<-.tokens’, ‘metadoc<-.corpus’, ‘metadoc<-.default’, ‘metadoc<-.dfm’, ‘metadoc<-.tokens’, ‘names<-.corpus’, ‘names<-.tokens’, ‘texts<-.corpus’, ‘View.default’, ‘View.dfm’, ‘View.kwic’, ‘as.DocumentTermMatrix.dfm’, ‘as.character.corpus’, ‘as.character.tokens’, ‘as.corpus.corpus’, ‘as.corpus.corpuszip’, ‘as.corpus.default’, ‘as.data.frame.dfm’, ‘as.data.frame.textstat_proxy’, ‘as.dfm.DocumentTermMatrix’, ‘as.dfm.Matrix’, ‘as.dfm.TermDocumentMatrix’, ‘as.dfm.data.frame’, ‘as.dfm.default’, ‘as.dfm.dfm’, ‘as.dfm.dfmSparse’, ‘as.dfm.matrix’, ‘as.dictionary.data.frame’, ‘as.dictionary.default’, ‘as.dictionary.dictionary2’, ‘as.fcm.Matrix’, ‘as.fcm.default’, ‘as.fcm.fcm’, ‘as.fcm.matrix’, ‘as.igraph.fcm’, ‘as.list.textstat_proxy’, ‘as.list.tokens’, ‘as.matrix.dfm’, ‘as.network.default’, ‘as.network.fcm’, ‘as.tokens.default’, ‘as.tokens.list’, ‘as.tokens.spacyr_parsed’, ‘as.tokens.tokens’, ‘as.wfm.dfm’, ‘as.yaml.dictionary2’, ‘bootstrap_dfm.character’, ‘bootstrap_dfm.corpus’, ‘bootstrap_dfm.default’, ‘bootstrap_dfm.dfm’, ‘c.corpus’, ‘c.tokens’, ‘cbind.dfm’, ‘char_ngrams.character’, ‘char_ngrams.default’, ‘char_segment.character’, ‘char_segment.default’, ‘char_tolower.character’, ‘char_tolower.default’, ‘char_tortl.character’, ‘char_tortl.default’, ‘char_toupper.character’, ‘char_toupper.default’, ‘char_trim.character’, ‘char_trimsentences.character’, ‘char_wordstem.character’, ‘char_wordstem.default’, ‘convert.corpus’, ‘convert.default’, ‘convert.dfm’, ‘corpus.Corpus’, ‘corpus.character’, ‘corpus.corpus’, ‘corpus.data.frame’, ‘corpus.default’, ‘corpus.kwic’, ‘corpus_reshape.corpus’, ‘corpus_reshape.default’, ‘corpus_sample.corpus’, ‘corpus_sample.default’, ‘corpus_segment.corpus’, ‘corpus_segment.default’, ‘corpus_subset.corpus’, ‘corpus_subset.default’, ‘corpus_trim.corpus’, ‘corpus_trimsentences.corpus’, ‘dfm.character’, ‘dfm.corpus’, ‘dfm.default’, ‘dfm.dfm’, ‘dfm.tokens’, ‘dfm_compress.default’, ‘dfm_compress.dfm’, ‘dfm_group.default’, ‘dfm_group.dfm’, ‘dfm_lookup.default’, ‘dfm_lookup.dfm’, ‘dfm_replace.default’, ‘dfm_replace.dfm’, ‘dfm_sample.default’, ‘dfm_sample.dfm’, ‘dfm_select.default’, ‘dfm_select.dfm’, ‘dfm_smooth.default’, ‘dfm_smooth.dfm’, ‘dfm_sort.default’, ‘dfm_sort.dfm’, ‘dfm_subset.default’, ‘dfm_subset.dfm’, ‘dfm_tfidf.default’, ‘dfm_tfidf.dfm’, ‘dfm_tolower.default’, ‘dfm_tolower.dfm’, ‘dfm_toupper.default’, ‘dfm_toupper.dfm’, ‘dfm_trim.default’, ‘dfm_trim.dfm’, ‘dfm_weight.default’, ‘dfm_weight.dfm’, ‘dfm_wordstem.default’, ‘dfm_wordstem.dfm’, ‘dictionary.default’, ‘dictionary.dictionary2’, ‘dictionary.list’, ‘docfreq.default’, ‘docfreq.dfm’, ‘docnames.corpus’, ‘docnames.default’, ‘docnames.dfm’, ‘docnames.readtext’, ‘docnames.spacyr_parsed’, ‘docnames.tokens’, ‘docvars.corpus’, ‘docvars.default’, ‘docvars.dfm’, ‘docvars.readtext’, ‘docvars.tokens’, ‘fcm.character’, ‘fcm.corpus’, ‘fcm.default’, ‘fcm.dfm’, ‘fcm.tokens’, ‘fcm_compress.default’, ‘fcm_compress.fcm’, ‘fcm_keep.default’, ‘fcm_keep.fcm’, ‘fcm_remove.default’, ‘fcm_remove.fcm’, ‘fcm_select.default’, ‘fcm_select.fcm’, ‘fcm_sort.default’, ‘fcm_sort.fcm’, ‘fcm_tolower.default’, ‘fcm_tolower.fcm’, ‘fcm_toupper.default’, ‘fcm_toupper.fcm’, ‘featfreq.default’, ‘featfreq.dfm’, ‘featnames.dfm’, ‘head.corpus’, ‘head.dfm’, ‘head.fcm’, ‘head.textstat_proxy’, ‘kwic.character’, ‘kwic.corpus’, ‘kwic.default’, ‘kwic.tokens’, ‘lengths.tokens’, ‘meta.corpus’, ‘meta.default’, ‘meta.dfm’, ‘meta.dictionary2’, ‘meta.tokens’, ‘metadoc.corpus’, ‘metadoc.default’, ‘metadoc.dfm’, ‘metadoc.tokens’, ‘ndoc.corpus’, ‘ndoc.default’, ‘ndoc.dfm’, ‘ndoc.readtext’, ‘ndoc.spacyr_parsed’, ‘ndoc.tokens’, ‘nfeat.default’, ‘nfeat.dfm’, ‘nscrabble.character’, ‘nscrabble.default’, ‘nsentence.character’, ‘nsentence.corpus’, ‘nsentence.default’, ‘nsentence.spacyr_parsed’, ‘nsentence.tokens’, ‘nsyllable.character’, ‘nsyllable.default’, ‘nsyllable.tokens’, ‘ntoken.character’, ‘ntoken.corpus’, ‘ntoken.default’, ‘ntoken.dfm’, ‘ntoken.spacyr_parsed’, ‘ntoken.tokens’, ‘ntype.character’, ‘ntype.corpus’, ‘ntype.default’, ‘ntype.dfm’, ‘ntype.spacyr_parsed’, ‘ntype.tokens’, ‘phrase.character’, ‘phrase.collocations’, ‘phrase.default’, ‘phrase.dictionary2’, ‘phrase.list’, ‘phrase.tokens’, ‘print.corpus’, ‘print.kwic’, ‘print.phrases’, ‘print.summary.corpus’, ‘print.tokens’, ‘rbind.dfm’, ‘sparsity.default’, ‘sparsity.dfm’, ‘summary.character’, ‘summary.corpus’, ‘tail.corpus’, ‘tail.dfm’, ‘tail.fcm’, ‘tail.textstat_proxy’, ‘textplot_keyness.default’, ‘textplot_keyness.keyness’, ‘textplot_network.dfm’, ‘textplot_network.fcm’, ‘textplot_wordcloud.default’, ‘textplot_wordcloud.dfm’, ‘textplot_xray.default’, ‘textplot_xray.kwic’, ‘texts.character’, ‘texts.corpus’, ‘texts.readtext’, ‘textstat_collocations.character’, ‘textstat_collocations.corpus’, ‘textstat_collocations.default’, ‘textstat_collocations.tokens’, ‘textstat_dist.default’, ‘textstat_dist.dfm’, ‘textstat_entropy.default’, ‘textstat_entropy.dfm’, ‘textstat_frequency.default’, ‘textstat_frequency.dfm’, ‘textstat_keyness.default’, ‘textstat_keyness.dfm’, ‘textstat_lexdiv.default’, ‘textstat_lexdiv.dfm’, ‘textstat_lexdiv.tokens’, ‘textstat_readability.character’, ‘textstat_readability.corpus’, ‘textstat_readability.default’, ‘textstat_select.default’, ‘textstat_select.textstat’, ‘textstat_simil.default’, ‘textstat_simil.dfm’, ‘tokens.character’, ‘tokens.corpus’, ‘tokens.default’, ‘tokens.list’, ‘tokens.tokens’, ‘tokens_chunk.tokens’, ‘tokens_compound.default’, ‘tokens_compound.tokens’, ‘tokens_lookup.default’, ‘tokens_lookup.tokens’, ‘tokens_ngrams.default’, ‘tokens_ngrams.tokens’, ‘tokens_replace.default’, ‘tokens_replace.tokens’, ‘tokens_sample.default’, ‘tokens_sample.tokens’, ‘tokens_segment.tokens’, ‘tokens_select.default’, ‘tokens_select.tokens’, ‘tokens_skipgrams.default’, ‘tokens_skipgrams.tokens’, ‘tokens_split.default’, ‘tokens_split.tokens’, ‘tokens_subset.default’, ‘tokens_subset.tokens’, ‘tokens_tolower.default’, ‘tokens_tolower.tokens’, ‘tokens_tortl.default’, ‘tokens_tortl.tokens’, ‘tokens_toupper.default’, ‘tokens_toupper.tokens’, ‘tokens_wordstem.default’, ‘tokens_wordstem.tokens’, ‘topfeatures.default’, ‘topfeatures.dfm’, ‘types.default’, ‘types.tokens’, ‘unlist.tokens’ were declared in NAMESPACE but not found”",
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "Error: package or namespace load failed for ‘quanteda’ in library.dynam(lib, package, package.lib):\n shared object ‘quanteda.so’ not found\n",
          "traceback": [
            "Error: package or namespace load failed for ‘quanteda’ in library.dynam(lib, package, package.lib):\n shared object ‘quanteda.so’ not found\nTraceback:\n",
            "1. library(pkg, character.only = TRUE)",
            "2. tryCatch({\n .     attr(package, \"LibPath\") <- which.lib.loc\n .     ns <- loadNamespace(package, lib.loc)\n .     env <- attachNamespace(ns, pos = pos, deps)\n . }, error = function(e) {\n .     P <- if (!is.null(cc <- conditionCall(e))) \n .         paste(\" in\", deparse(cc)[1L])\n .     else \"\"\n .     msg <- gettextf(\"package or namespace load failed for %s%s:\\n %s\", \n .         sQuote(package), P, conditionMessage(e))\n .     if (logical.return) \n .         message(paste(\"Error:\", msg), domain = NA)\n .     else stop(msg, call. = FALSE, domain = NA)\n . })",
            "3. tryCatchList(expr, classes, parentenv, handlers)",
            "4. tryCatchOne(expr, names, parentenv, handlers[[1L]])",
            "5. value[[3L]](cond)",
            "6. stop(msg, call. = FALSE, domain = NA)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 1: ï»\n# ref https://stackoverflow.com/questions/20889996/how-do-i-remove-all-non-ascii-characters-with-regex-and-notepad:\n# > duh<-read.table(fname, stringsAsFactors=FALSE)\n# > duh[,1]\n# [1] \"4+2\" \"ï»\"  \"3+6\"\n# > sub(\"[^\\x1F-\\x7F]+\", \"\", duh[,1])\n# [1] \"4+2\" \"\"    \"3+6\"\n\n# https://wesslen.github.io/assets/documents/papers/tmm.pdf guides choices, for new users too. It says:\n# [(1) hypothesis and question formation, (2) design and data collection, (3) data pre-processing, and (4) topic modeling]\n# For Project Occipital:\n# (1) Hypothesis: there are features of a question that explain its difficulty, as evidenced by JEE-Advanced data.\n# Features include topics associated with a question.  Those (latent) topic features can be modeled by non-expert humans.\n# Those topic features explain difficulty over and above question type and marking scheme.  Those impact estimates\n# are what the world misses knowing to subsequently (reproducibly) inform teaching-learning of a population.\n# (2) Already addressed by the Project.\n# (3) Let's begin:\n\n# cWorkDir <- paste0(path.expand(\"~\"), \"/../Desktop/preBachelors/www/solnJEEAdvanced\")\ncFile.noOCR <- paste0(cWorkDir, \"/jads-nocr.rds\")\ncFile.OCR <- paste0(cWorkDir, \"/jads-ocr.rds\")\ncFF <- \"\\r\\n\\f\" # Form Feed or Page Break\nconcatPages <- function(jads){ # while maintaining each file as distinct\n  print(str(jads))\n  jads.out <- jads\n  for(iFile in 1:length(jads.out)){\n    jads.out[[iFile]] <- paste(jads.out[[iFile]], collapse=cFF)\n  }\n  print(str(jads.out))\n  return(jads.out)\n}\ncYPCSubSec.order <- 1:5 # order of YPCSubSec\ncYPCSubSec <- list(\n  patY=\"201[[:digit:]]\", # Year. \"2007\", \"2067\", \\n\"2016\" also occur in files.\n    # [[:digit:]] is portable, not [0-9]\n  patP=\"PAPER[^\\r\\n]*[12]\", # (PAPER|SHIFT) Paper or Shift. '^' sometimes is negation.\n  patC=\"CODE[^\\r\\n]*[[:digit:]]{1,2}\", # Code, which varies ordering of questions for the same Paper\n  patSub=\"PART[^\\r\\n]*[I]{1,3}[^\\r\\n]* | PHYSICS | CHEMISTRY | MATH\", # PART...Subject, possibly till end of line (not $).\n  patSec=\"SECTION[^\\r\\n]*[[:digit:]]\") # Section within Paper*Subject, possibly till end of line (not $).\ncPatQOS <- list(\n  \"(Q\\\\.[123456789][[:digit:]]*|[123456789][[:digit:]]*\\\\.[[:space:]])\",\n    # beware: \"[123456789][[:digit:]]*\\\\.[^[:digit:]]\" matches \"7.B\" too; so \"[[:space:]]\" instead of \"not digit\".\n    # Question: Q.1 or 1; sometimes *Q.1 coz indicating 11th std portions. \"100.\" spuriously matched.\n    # [\\< and \\> match the empty string at the beginning and end of a word.] but POSIX locale whereas Windows C locale!\n    # [^0[:digit:]] instead of less-portable [1-9], but negates 0 as well as any digit!\n    # was: \"(Q\\\\.[123456789][[:digit:]]*|[123456789][[:digit:]]*\\\\.)\" but matched 2.00 wrongly.\n    # was: \"^[*]?Q\\\\.[123456789][[:digit:]]|^[123456789][[:digit:]]\\\\.\"\n    # was: \"Q\\\\.[123456789][[:digit:]]|[123456789][[:digit:]]\\\\.[[:space:]]\"\n  \"\\\\(A)\", # Options. \"(A)\" is treated as a parenthesized regular expression!\n    # was: \"^[[:space:]]*\\\\(A)\"\n    # was: \"^\\\\(A)\", \"[[:space:]]*\\\\(A\\\\)[[:space:]]+\"\n  \"(Sol|Ans)\") # (Answer-key ie correct Option and) Solution\n    # was: \"^(Sol|Ans)\"\n    # [regexpr and gregexpr support 'named capture'. If groups are named, e.g., \"(?<first>[A-Z][a-z]+)\"\n    # then the positions of the matches are also returned by name.]\nmyregmatches.jad <- function(jads, j, locYPCSubSec, wantUniquePattern){\n  ans.jad <- list()\n  for(iYPCSubSec in 1:length(locYPCSubSec)){\n    ans.jad[[iYPCSubSec]] <- regmatches(jads[j], locYPCSubSec[[iYPCSubSec]][j])\n    if(iYPCSubSec %in% wantUniquePattern){\n      ans.jad[[iYPCSubSec]] <- list(unique(ans.jad[[iYPCSubSec]][[1]]))\n    } # else continue\n  }\n  return(ans.jad)\n}\nmyregmatches <- function(jads, locYPCSubSec, wantUniquePattern){\n  ans <- list()\n  for(j in 1:length(jads)){\n    ans[[j]] <- myregmatches.jad(jads, j, locYPCSubSec, wantUniquePattern)\n  }\n  return(ans)\n}\nlocatePattern <- function(jads, pattern){\n  locPattern <- list()\n  for(iPattern in 1:length(pattern)){\n    locPattern[[iPattern]] <- gregexpr(pattern[[iPattern]], jads)\n      # alt: gregexpr() for global; or regexec() for first match.\n      # [fixed = FALSE, perl = FALSE: use POSIX 1003.2 extended regular expressions (the default).]\n      # Regarding substring():\n      # [These functions are often used with nchar to truncate a display. That does not really work (you want to limit\n      # the width, not the number of characters, so it would be better to use strtrim), but at least make sure you use\n      # the default nchar(type = \"c\").]\n  }\n  return(locPattern)\n}\nmyPDFtoOCR <- function(files, iFiles){\n  for(iFile in iFiles){\n    pngfile <- pdftools::pdf_convert(files[iFile], dpi=600)\n    # Converting page 1 to ocrscan_1.png... done!\n    text <- tesseract::ocr(pngfile)\n    print(sum(nchar(text))); print(glimpse(text))\n    catext <- concatPages(list(text))\n    print(nchar(catext)); print(glimpse(catext))\n    fname <- paste0(substring(files[iFile], first=1, last=(nchar(files[iFile]) - 4)), # default: last = 1000000L\n      \"-ocr.rds\")\n    saveRDS(catext, file=fname) # preferable over save() coz readRDS() \"functional\" and not\n      # attached to earlier object names. default: ascii=FALSE which might be more portable but less efficient.\n    # catext2 <- readRDS(file=fname); identical(catext2, catext)\n  }\n  return()\n}\nmyChooseFiles <- function(wd=paste0(cWorkDir, \"/*.*\"), filext=c(\"pdf\", \"All\")){\n  if(interactive() && .Platform$OS.type == \"windows\"){\n    files <- choose.files(default=wd, filters=Filters[filext,])\n  } else { # error, for now!\n    stop()\n  }\n  # alt: list.files(pattern=\"pdf$\")\n  # following fails likely coz extended regular expressions haven't been selected somewhere; or locale matters.\n  # list.files(mywd, pattern=\"*20[0-9]{2}*[.]pdf\", recursive=FALSE, include.dirs=FALSE, no..=TRUE)\n  #   [:digit:] depends on POSIX locale.\n  return(files)\n}\nmyChoosePDFnoOCR <- function(){\n  # ref https://uvastatlab.github.io/2019/05/14/reading-pdf-files-into-r-for-text-mining/\n  files <- myChooseFiles(filext=c(\"pdf\"))\n  jads <- lapply(files, pdf_text)\n  # [PDF error: Expected the optional content group list, but wasn't able to find it, or it isn't an Array].\n  # Ignore such (harmless) errors coz [The required key /OCGs is indeed missing] from some .pdf files, as per\n  # ref paste0(\"https://tex.stackexchange.com/questions/66108\",\n  #   \"/syntax-error-expected-the-optional-content-group-list-but-wasnt-able-to-find\")\n  print(length(jads)); print(lapply(jads, nchar))\n  # (3b.1) Concat the pages. Stray headers/footers might have to be dropped; later.\n  jads <- concatPages(jads)\n  for(iFile in 1:length(files)){\n    fname <- paste0(substring(files[iFile], first=1, last=(nchar(files[iFile]) - 4)), # default: last = 1000000L\n      \"-noc.rds\") # not OCR\n    saveRDS(jads[iFile], file=fname) # jads[[iFile]] is a char string, whereas we want a list containing that\n      # (char string) for consistency\n  }\n  return(files)\n}\nmyreadRDS <- function(files){\n  # jads <- list()\n  # for(iFile in 1:length(files)){\n  #   jads[[iFile]] <- readRDS(file=files[iFile])\n  # }\n  jads <- lapply(files, readRDS)\n  return(jads)\n}\nmyunlist <- function(nestedList){\n  # ref https://stackoverflow.com/questions/16300344/how-to-flatten-a-list-of-lists\n  ans <- unlist(nestedList, recursive=FALSE)\n  return(ans)\n}\nsubstrXY <- function(Xi, Yi, moreArgsList){\n  stopifnot(length(moreArgsList) == 1)\n  ans <- substring(moreArgsList[[1]], first=Xi, last=Yi)\n  return(ans)\n}\nsubstringQOS <- function(jad, iChars){\n  iChars.len <- length(iChars)\n  stopifnot(iChars.len >= 2)\n  QOSs <- mapply(FUN=substrXY, X=iChars[1:(iChars.len-1)], Y=(iChars[2:(iChars.len)] - 1),\n    MoreArgs=list(jad), SIMPLIFY=TRUE, USE.NAMES=TRUE)\n    # last= # iChars + attr(iChars, \"match.length\"))\n  return(QOSs)\n}\nmySaveQOSs <- function(jads, locQOS, forOCR=FALSE,\n  mustWrite=FALSE){\n  QOSs <- mapply(FUN=substringQOS, jads, locQOS[[1]], # list of vectors of int where matched. was: jads[[1]]\n    MoreArgs=NULL, SIMPLIFY=TRUE, USE.NAMES=TRUE)\n  if(mustWrite){\n    fname <- paste0(cWorkDir, \"/jads-\", ifelse(forOCR, \"ocr\", \"nocr\"), \"-qos.rds\")\n    saveRDS(QOSs, file=fname) # default: ascii=FALSE.\n  } # else continue\n  return(QOSs)\n}\nlist2matrix <- function(aList){\n  # ref https://\n  # stackoverflow.com/questions/15201305/how-to-convert-a-list-consisting-of-vector-of-different-lengths-to-a-usable-data\n  n.obs <- sapply(aList, length)\n  seq.max <- seq_len(max(n.obs))\n  mat <- t(sapply(aList, \"[\", i = seq.max))\n  return(mat)\n}\nmylocQ.toCSV <- function(locQ,\n  fname=paste0(cWorkDir, \"/jads-\", ifelse(forOCR, \"ocr\", \"nocr\"), \"-locQOS.csv\")){\n  locQm <- list2matrix(locQ)\n  # alt: as.dataframe() [If a list is supplied, each element is converted to a column in the data frame.]\n  write.csv(locQm, file=fname)\n  return()\n}\ncCharWidth <- 11 # Count of chars to display in window.\nheadCharVec <- function(chvec, n=cCharWidth){\n  ans <- substring(chvec, first=1, last=n)\n  # print(ans)\n  return(ans)\n}\nmergeCharVec <- function(chVec, mergeSpecs, collapseChar=\" \"){\n  mergedVec <- c()\n  imv <- 1; ich <- 1; jms <- 1\n  while(ich <= length(chVec)){\n    if(jms <= length(mergeSpecs)){\n      mspec <- mergeSpecs[[jms]]\n    } else {\n      mspec <- c()\n    }\n    if(ich %in% mspec){\n      mergedVec[imv] <- paste0(chVec[mspec], collapse=collapseChar) # was: collapse=\"\" which showed words without spaces!\n      ich <- max(mspec) + 1\n      jms <- jms + 1\n    } else {\n      mergedVec[imv] <- chVec[ich]\n      ich <- ich + 1\n      # jms stays as is.\n    }\n    imv <- imv + 1\n  }\n  return(mergedVec)\n}\nmoreChVec <- function(chVec, ichVec, n=350){\n  print(nchar(chVec[ichVec])); print(paste(\"showing nchar=\", n))\n  print(headCharVec(chVec[ichVec], n))\n  return()\n}\ncPattern.PfQ <- \"Paragraph for Question\"\ncPattern.qNum1 <- \"^([[:digit:]]+[.]|Q[.][[:digit:]]+)\" # \"13.\" or \"Q.13\" are valid forms.\nmyPrefixPostQnum <- function(prefix, ontoString, patternQnum=cPattern.qNum1){\n  # qnum <- substring(ontoString, first=1, last=3) # or 4.\n  qnumReplacement <- paste0(\"\\\\1 \", prefix) # was: \"\\\\1 \". Shouldn't the new blank/space be dropped?\n  ans <- sub(pattern=patternQnum, replacement=qnumReplacement, x=ontoString, fixed=FALSE)\n  # [include backreferences \"\\1\" to \"\\9\" to parenthesized subexpressions of pattern.]\n  return(ans)\n}\nmultMetaSelectedQOSs <- function(till.imetaYPq, metaYPq, mcv){\n  mmsqoss <- lapply(1:till.imetaYPq, FUN=metaSelectedQOSs, metaYPq, mcv)\n  return(mmsqoss)\n}\nmetaSelectedQOSs <- function(imetaYPq, metaYPq, mcv){\n  iSelectVec <- metaYPq[[imetaYPq]]$iMerged\n  msqoss <- mcv[iSelectVec] # ...[[1]]$iMerged==1:61\n  # write.table(msqoss, file=fname, append=TRUE, row.names=FALSE, col.names=FALSE) # Beware: append= here.\n  return(msqoss)\n}\nmyCollapseQ <- function(absRowNum, countRows, qoss.upd, mySep=\"\"){\n  stopifnot(countRows >= 2) # else no need to collapse.\n  ans <- paste0(qoss.upd[absRowNum:(absRowNum + countRows - 1),], collapse=mySep) # was: [,1].\n  return(ans)\n}\ngetNextQOS <- function(relativeRowNum, zeroRowNum, qoss.upd, metaYP){\n  chrrNum <- paste0(\"r\", relativeRowNum)\n  ans <- switch(metaYP, # Beware: switch() behaves distinctly for EXPR char vs. integer. Latter args needed in sequence.\n    Y2013P2 = Y2013P2.getNextQOS(chrrNum, relativeRowNum, zeroRowNum, qoss.upd, metaYP),\n\n    # default case for metaYP:\n    do.call(paste0(metaYP, \".getNextQOS\"), args=list(chrrNum, relativeRowNum, zeroRowNum, qoss.upd, metaYP),\n      quote=FALSE)\n    # try(do.call()); upon failure stop(paste(metaYP, \"unknown\"))\n  )\n  mnxtq <- ans[! is.na(ans)]\n  return(mnxtq)\n}\ngetAllQOS <- function(absoluteRowNums, zeroRowNum, qoss.upd, metaYP){\n  relativeRowNums <- absoluteRowNums - zeroRowNum # zeroRowNum is an offset.\n  allQOS <- lapply(relativeRowNums, FUN=getNextQOS, zeroRowNum, qoss.upd, metaYP)\n  return(unlist(allQOS))\n}\ntextOptionOCR <- function(forOCR){\n  return(ifelse(forOCR, \"ocr\", \"nocr\"))\n}\nold.putFileQOSs <- function(qoss, prefix=paste0(cWorkDir, \"/jads-\"), fromOCR=TRUE, suffix=\"-QOSs\", ext=\".csv\"){\n  # use .rds instead of problematic .csv for QOS and other strings. So, rewrite following code before reuse:\n  fname <- paste0(prefix, textOptionOCR(fromOCR), suffix, ext); print(fname)\n  write.table(NULL, file=fname, append=FALSE, row.names=FALSE, col.names=FALSE)\n  for(i in 1:length(qoss)){\n    # was: concatPages(qoss) but that places QOSs into one char string collapsed by cFF.\n    # whereas each QOS is to be seen as a Document for Topic Modeling.\n    qosVec <- qoss[[i]]\n    # alt: write.table(qosVec, file=fname, append=TRUE, row.names=FALSE, col.names=FALSE) # Beware: append=TRUE here.\n    # till 2020Feb02 was:\n    for(j in 1:length(qosVec)){\n      write.table(qosVec[j], file=fname, append=TRUE, row.names=FALSE, col.names=FALSE) # Beware: append=TRUE here.\n    }\n  }\n  return()\n}\nputFileQOSs <- function(qoss, prefix=paste0(cWorkDir, \"/datJADqos-\"), fromOCR=TRUE, suffix=\"\", ext=\".rds\"){\n  fname <- paste0(prefix, textOptionOCR(fromOCR), suffix, ext); print(fname)\n  saveRDS(qoss, file=fname) # default: ascii=FALSE.\n  return()\n}\ngetFiledQOSs <- function(prefix=paste0(cWorkDir, \"/datJADqos-\"), fromOCR=TRUE, suffix=\"\", ext=\".rds\", doUnlistRec=TRUE){\n  # (fromOCR=c(TRUE, FALSE), ext=c(\".rds\", \".csv\"))\n  fname <- paste0(prefix, textOptionOCR(fromOCR), suffix, ext); print(fname)\n  qoss <- if(ext == \".rds\"){\n    dat.rds <- myreadRDS(fname)\n    if(doUnlistRec){\n      dat.rds.flat <- unlist(dat.rds, recursive=TRUE) # alt: myunlist(myunlist(dat.rds))\n    } else {\n      dat.rds.flat <- dat.rds\n    }\n    dat.rds.flat.df <- as.data.frame(dat.rds.flat, stringsAsFactors=FALSE)\n  } else { # \".csv\" or other ext.\n    read.table(file=fname, header=FALSE, stringsAsFactors=FALSE)\n  }\n  print(dim(qoss)); print(str(qoss))\n  return(qoss)\n}\ngetMetaSubjectsVec <- function(y, metaYPq, whichSubs=c(\"P\", \"C\", \"M\")){\n  subvec <- c() # init\n  # subnames <- names(metaYPq[[y]])\n  my <- metaYPq[[y]]\n  for(asub in whichSubs){\n    subvec[my[[asub]]] <- asub # names(my[[asub]])\n  }\n  return(subvec)\n}\nmetaToVars <- function(metaYPq, whichSubs=c(\"P\", \"C\", \"M\")){\n  yvec <- c() # init\n  # names(metaYPq[[names(metaYPq)[1]]])\n  Ys <- names(metaYPq)\n  YsSubjectsVec <- lapply(Ys, FUN=getMetaSubjectsVec, metaYPq, whichSubs=whichSubs)\n  for(i in 1:length(Ys)){\n    yvec <- c(yvec, rep(Ys[i], times=length(YsSubjectsVec[[i]])))\n  }\n  YsSubjectsVec.flat <- unlist(YsSubjectsVec, recursive=TRUE)\n  mvarsdf <- data.frame(subject=YsSubjectsVec.flat, YP=yvec)\n  return(mvarsdf)\n}\npasteYP <- function(ivec, YPchrvec){\n  ivec3 <- ivec * 3\n  ans <- paste0(YPchrvec[ivec3 - 1], YPchrvec[ivec3])\n  return(ans)\n}\nYPintvec <- function(YPchrvec){\n  yyyy.p.vec <- unlist(strsplit(YPchrvec, split=\"Y|P\"))\n  stopifnot(length(yyyy.p.vec) == 3*length(YPchrvec))\n  yyyypvec <- unlist(lapply(1:(length(yyyy.p.vec) / 3), FUN=pasteYP, yyyy.p.vec))\n  # yyyypvec <- paste0(yyyy.p, collapse=\"\") # alt: paste0(yyyy.p[2], yyyy.p[3])\n  ans <- as.integer(yyyypvec)\n  return(ans)\n}\nYPint <- function(YPchr){\n  yyyy.p <- unlist(strsplit(YPchr, split=\"Y|P\"))\n  stopifnot(length(yyyy.p) == 3)\n  yyyyp <- paste0(yyyy.p, collapse=\"\") # alt: paste0(yyyy.p[2], yyyy.p[3])\n  ans <- as.integer(yyyyp)\n  return(ans)\n}\nthoughtQuotesForTopicPair <- function(anSTMfit, topics=c(1,2), shortdoc, nCovar=3){\n  # There would be example documents highly associated with given topics (pair). This prints them to a graphics device.\n  thoughts1 <- findThoughts(anSTMfit, texts = shortdoc, n = nCovar,\n    topics[1])$docs[[1]]\n  thoughts2 <- findThoughts(anSTMfit, texts = shortdoc, n = nCovar,\n    topics[2])$docs[[1]]\n  op <- par(mfrow = c(1, length(topics)), mar = c(0.5, 0.5, 1, 0.5))\n  plotQuote(thoughts1, width = 30, main = paste0(\"Topic \", topics[1]))\n  plotQuote(thoughts2, width = 30, main = paste0(\"Topic \", topics[2]))\n  # At end of plotting, reset to previous settings:\n  par(op)\n  return()\n}\nthoughtQuotesForTopicVec <- function(anSTMfit, topics=c(1,2), shortdoc, nMostAssociatedDocs=5){\n  # There would be example (nCovar count of) documents highly associated with given topics (vector).\n  # This prints them to a graphics device.\n  thoughts <- findThoughts(anSTMfit, texts = shortdoc, n=nMostAssociatedDocs, topics)\n    # Complex queries eg [where = treatment==1 & Topic2>.2] are possible.\n    # [Returns the top n documents ranked by the MAP estimate of the topic's theta value (which captures the modal\n    # estimate of the proportion of word tokens assigned to the topic under the model).]\n  op <- par(mfrow = c(1, length(topics)), mar = c(0.5, 0.5, 1, 0.5))\n  # plot(NULL, main=paste0(\"Topics \", paste0(min(topics), \":\", max(topics)))\n  plot(thoughts, main=paste0(\"Topics \", paste0(min(topics), \":\", max(topics))))\n    # Beware: main= repeats on sub-plots, and title= did not place any title :-(.\n    # plot() plots 1 thoughts (ie its associated docs) at a time. That's why the par() prior.\n  # alt: lapply(thoughts$docs, FUN=plotQuote)\n  # plotQuote(thoughts$docs[[1]], width = 30, main = paste0(\"Topics \", paste0(topics, collapse=\",\")))\n  # thoughts$docs[[1]][2:3] to select a subset of examples.\n  # At end of plotting, reset to previous settings:\n  par(op)\n  return(thoughts)\n}\nvisNetworkCorrel <- function(ctmFit, topicNames, topic){\n  # Let's create a network correlation plot. We’ll use a static network first.\n\n  library(igraph); library(visNetwork)\n\n  # Beware: topic from tmFit, where stmFit topics differ from ctmFit ones.\n  # Maybe this works only for ctmFit, not stmFit coz:\n  # [Error in apply(topicNames$prob, 1, function(x) paste0(x, collapse = \" \\n \")) : \n  #  dim(X) must have a positive length]\n  # but fails there too.\n  mod.out.corr <- topicCorr(ctmFit, cutoff=.01); plot(mod.out.corr)\n\n  # output links and simplify\n  links2 <- as.matrix(mod.out.corr$posadj)\n  net2 <- graph_from_adjacency_matrix(links2, mode = \"undirected\")\n  net2 <- igraph::simplify(net2) \n\n  # create the links and nodes\n  links <- igraph::as_data_frame(net2, what=\"edges\")\n  nodes <- igraph::as_data_frame(net2, what=\"vertices\")\n\n  # set parameters for the network\n  nodes$shape <- \"dot\"  \n  nodes$title <- paste0(\"Topic \", topic$TopicNumber)\n  nodes$label <- apply(topicNames$prob, 1, function(x) paste0(x, collapse = \" \\n \")) # Node label\n  nodes$size <- (topic$TopicProportions / max(topic$TopicProportions)) * 30\n  nodes$font <- \"18px\"\n  nodes$id <- as.numeric(1:k)\n\n  visNetwork(nodes, links, width=\"100%\",  height=\"800px\", main=\"Topics\") %>% \n    visOptions(highlightNearest = list(enabled = TRUE, algorithm = \"hierarchical\")) %>%\n    visNodes(scaling = list(max = k)) %>% # was: 60.\n    visIgraphLayout(smooth = T) %>%\n    visInteraction(navigationButtons = T)\n\n  return()\n}\nupdateMergedCharVec <- function(mcv){\n    # - Define Y2012P2.get*() that post-processes to *move* ParaForQuestions into Qs where missed; then drops exclusive\n    #   paras since they are not Qs completely and have no separate ID.\n    # move PfQ in mcv[73,76,79] into corresponding following 2 char strings. Then empty those PfQs. Then update metaYPq.\n    para0910 <- mcv[73]\n    q09 <- sub(pattern=\"9,\", replacement=\"9.\", x=mcv[74]) # coz \"9,\" at start makes myPrefixPostQnum() miss pasting PfQ!\n    q09 <- myPrefixPostQnum(para0910, q09)\n    q10 <- myPrefixPostQnum(para0910, mcv[75])\n    para1112 <- mcv[76]\n    q11 <- myPrefixPostQnum(para1112, mcv[77])\n    q12 <- myPrefixPostQnum(para1112, mcv[78])\n    para1314 <- mcv[79]\n    q13 <- myPrefixPostQnum(para1314, mcv[80])\n    q14 <- myPrefixPostQnum(para1314, mcv[81])\n    mcv[73:81] <- c(\"\", q09, q10, \"\", q11, q12, \"\", q13, q14)\n    return(mcv)\n}\nmyConvUTF8 <- function(x){\n  Encoding(x) <- \"UTF-8\" # alt: \"latin1\"\n  xx <- iconv(x, \"UTF-8\", \"UTF-8\", sub='') ## replace any non UTF-8 by ''\n  return(xx)\n\n  # mydata[,2:3] <- apply(mydata[,2:3], 2, function(x) iconv(x, to=\"utf-8\"))\n  # ref https://stackoverflow.com/questions/17291287/how-to-identify-delete-non-utf-8-characters-in-r:\n  # x <- \"fa\\xE7ile\"\n  # Encoding(x) <- \"UTF-8\"\n  # iconv(x, \"UTF-8\", \"UTF-8\",sub='') ## replace any non UTF-8 by ''\n  # \"faile\"\n  # Here note that if we choose the right encoding:\n  # x <- \"fa\\xE7ile\"\n  # Encoding(x) <- \"latin1\"\n  # xx <- iconv(x, \"latin1\", \"UTF-8\",sub='')\n  # facile\n}\nmySTMlabeltype <- function(model){\n  # ref https://github.com/bstewart/stm/blob/master/R/labelTopics.R\n  # ref https://github.com/mroberts/stmBrowser/blob/master/R/stmBrowser.R\n  logbeta <- model$beta$logbeta\n  #make a switch for presence of content covariate\n  aspect <- length(logbeta)>1\n  labt <- ifelse(!aspect, \"prob\", # alt: \"frex\", \"lift\", \"score\".\n    \"topics\") # coz content covariates are present and demanded a different structure.\n  return(labt)\n}\njoinOCRqaNum <- function(qoss.meta, dmc2.ordYPq){\n  qm.idVec <- 1:nrow(qoss.meta)\n  dmc2o.ocrqaNum <- dmc2.ordYPq$ocrqaNum\n  jtKey <- intersect(qm.idVec, dmc2o.ocrqaNum); print(length(jtKey)) # 677 till Y2018P2. was: 357 till Y2014P2.\n  jtDiff <- setdiff(qm.idVec, dmc2o.ocrqaNum); print(length(jtDiff)); print(jtDiff)\n    # length==7.  82 120 496 509 539 569 571.\n  # print(dmc2.ordYPq[dmc2.ordYPq$ocrqaNum %in% c(71,82,120),]) # See some known missing rows.\n  jtdf <- cbind(qoss.meta[jtKey,], dmc2.ordYPq[dmc2o.ocrqaNum %in% jtKey,])\n    # Beware: jtKey is not row number coz intersect() returns common elements, not their locations, and any way,\n    # row numbers might not match across the two structures being merged! So, dmc2.ordYPq[jtKey,] is not ok to merge with!\n  # grep(\"subject\", colnames(responses.orig))\n  # stopifnot(jtdf[,2] == jtdf[,4]) # & more...\n  print(str(jtdf))\n  return(jtdf)\n}\nmyCategorize <- function(xvec, redPreProb=0.25, redLabel=\"below\", otherLabel=\"above\"){\n  xvecGrp <- c()\n  # TBD include its binary covariate too, (i) cut at *rOtot* 10th or 25th percentile and (ii) later level for red.\n  cutAt <- quantile(xvec, prob=redPreProb)\n  xvecIsPreProb <- (xvec <= cutAt) # TRUE for red zone coz redPreProb denotes red Pre Probability.\n  xvecGrp[xvecIsPreProb] <- paste0(redLabel, redPreProb*100, \"tile\")\n  xvecGrp[! xvecIsPreProb] <- paste0(otherLabel, redPreProb*100, \"tile\")  \n  return(xvecGrp)\n}\ngetJADdata <- function(suffix=paste0(\"till\", cYPtill), # was: suffix=paste0(\"-till\", cYPtill)\n  meta=\"metaVars\", fromOCR=TRUE, fname.meta2=\"\"){\n  mySuffix <- paste0(\"-\", suffix)\n  datqoss <- getFiledQOSs(prefix=paste0(cWorkDir, \"/jads-\"), fromOCR=TRUE, suffix=mySuffix, ext=\".rds\")\n  colnames(datqoss) <- \"QOS\" # Note: corresponding \"tmp\" file column name indicates date and time saved.\n  # file.qossTxt <- paste0(cWorkDir, \"/tmpQOSjads-\", textOptionOCR(fromOCR), mySuffix, \".txt\")\n  # write.table(datqoss, file=file.qossTxt)\n  fname.meta1 <- paste0(cWorkDir, \"/jads-\", textOptionOCR(fromOCR), mySuffix, meta, \".csv\")\n    # prefix=paste0(cWorkDir, \"/jads-\"), fromOCR=TRUE, suffix=paste0(mySuffix, meta), ext=\".csv\"\n  datmeta1 <- read.csv(file=fname.meta1)\n  print(str(datmeta1))\n  qoss.meta <- cbind(datqoss, datmeta1); print(str(qoss.meta))\n  # read.table(file=fname.meta1, col.names=FALSE, stringsAsFactors=FALSE) # stringsAsFactors=TRUE gets factors!\n\n  # fname.meta2 <- fname.meta.relPath\n  datmeta2 <- read.csv(file=fname.meta2)\n  print(str(datmeta2))\n  # datmeta2$YP <- YPintvec(as.character(datmeta2$YP)) # for continuous-time modeling data as input to STM later.\n  colnames(datmeta2) <- sub(pattern=paste0(\"tmpQOSjads.ocr.\", suffix), # was: mySuffix, \"tmpQOSjads.ocr.tillY2014P2\",\n    replacement=\"ocrqaNum\", x=colnames(datmeta2))\n    # was: ,\"jeeadvqaNum\",\"jeeadvqaType\",\"jeeadvmarkScheme\")]) <- c(\"ocrqaNum\",\"jeeqaNum\",\"jeeqaType\",\"jeemarkScheme\")\n  # cols.meta2 <- c(\"subject\",\"paper\",\"year\", # drop {qaNum,qaType,markScheme,right,tot}\n  #   \"uOtot\",\"rOtot\",\n  #   \"ocrqaNum\",\"jeeadvqaNum\",\"jeeadvqaType\",\"jeeadvmarkScheme\",\"YP\")\n  cols.meta2 <- colnames(datmeta2) # retain {right, tot} too for any subsequent modeling with/without topics!\n  levels(datmeta2$subject) <- toupper(substring(levels(datmeta2$subject), first=1, last=1)) # alt: c(\"C\",\"M\",\"P\")\n  # datmeta2$subject <- as.character(datmeta2$subject) # coz factor.\n  print(str(datmeta2))\n\n  # Subset datmeta2[, cols.meta2] with matching row numbers of qoss.meta *and* in same order, which might differ at start.\n  # Then with satisfied assertions, attempt merge.\n  dmc2 <- datmeta2[, cols.meta2]\n  dmc2 <- dmc2[which(! is.na(dmc2$ocrqaNum)),] # Drop those NAs.\n    # Beware: \"obsolete\" levels might still be around, if datmeta2 has incomplete data eg missing some years.\n  # stopifnot(levels(dmc2))\n  print(str(dmc2))\n  dmc2.ordYPq <- dmc2[order(dmc2$ocrqaNum, decreasing=FALSE),]\n    # Was: dmc2[order(dmc2$YP, dmc2$ocrqaNum, decreasing=FALSE),]\n    # within each YP *and* in (PCM) order matching qoss$subject order, which is how it appeared in the\n    # QOS *Solution* question papers. Beware: this will not match the JEE-Advanced questions' order in their question\n    # papers!!\n    # [For factors, this sorts on the internal codes, which is particularly appropriate for ordered factors.]\n  print(head(dmc2.ordYPq)); print(tail(dmc2.ordYPq))\n  # Drop qoss NAs too? BUT no use holding (eventually few) QOS rows that don't have this meta data?? Or is there?\n  qoss.meta12 <- joinOCRqaNum(qoss.meta, dmc2.ordYPq)\n  stopifnot(qoss.meta12[,2] == qoss.meta12[,10]) # subject cols match.\n  stopifnot(qoss.meta12[,3] == qoss.meta12[,27]) # YP cols match.\n    # Was: [Error ...   level sets of factors are different]. But that's coz one col has till Y2018 and so is ok.\n  cols2drop <- c(10,27,13:15,28:30)\n    # [1] 10 27 13 14 15 28 29 30\n  qoss.meta12 <- qoss.meta12[, -cols2drop]\n\n  # TBD notrOtot3=(1-rOtot)*10^3 as continuous covariate, considering red in colour scheme of stmBrowser().\n  qoss.meta12 <- cbind(qoss.meta12,\n    uOtot3=round((10^3)*qoss.meta12$uOtot, 0),\n    rOtot3=round((10^3)*qoss.meta12$rOtot, 0),\n    notrOtot3=round((1 - qoss.meta12$rOtot)*(10^3), 0),\n      # as continuous covariate, considering red in colour scheme of stmBrowser() to visualize topic interactions.\n    rOtotGrp=myCategorize(xvec=qoss.meta12$rOtot, redPreProb=0.25),\n    idYPSQ=paste0(qoss.meta12$YP, qoss.meta12$subject, qoss.meta12$jeeadvqaNum))\n      # Was: paste0(qoss.meta12$YP, \"Q\", qoss.meta12$jeeadvqaNum)\n      # JEE-Advanced papers' question number, which is unique\n      # within that YP's subject for sure, but not necessarily across subjects for that YP coz numbering for each\n      # YP's subject restarts from 1!  Beware!\n  return(qoss.meta12)\n\n  # TBD on 2020Feb18:\n  # - Remind to update JEEinsight, considering meta-data {qaType, markScheme} inconsistencies.\n  # - DONE: Append columns {uOtot3, rOtot3} as as.integer(round((10^3)*?, 0))\n  # - DONE: Code the merge/join on (YP, possibly with subject) in *row sequence* where ==60.\n  #   Else (eg for Y2012P2) match jeeqaNum with row#.\n  # - DONE: Define Y2012P2.get*() that post-processes to *move* ParaForQuestions into Qs where missed; drops exclusive\n  #   paras since they are not Qs completely and have no separate ID.\n  # - DONE: put*() those 60*6 into datmeta1 .rds. Update meta file too to change 63 rows for Y2012P2 Physics back to 60.\n  # - DONE: rename .R files suitably and reflect that into source() stmts.\n  # Beware:\n  # - QOS tmpQOSjads-ocr-tillY2014P2.txt {69,72,75} missed in outJADinsight. Also, relying on *row* numbers for QOS!\n  # - 2012P2 Chemistry qaNum {3/23} missed in outJADinsight; that would have be QOS tmpQOSjads-ocr-tillY2014P2.txt {85-3}.\n  #     Its Maths qaNum {20/60} missed in outJADinsight; that would have been QOS tmpQOSjads-ocr-tillY2014P2.txt {123-3}.\n}\ndropPattern <- function(pattern, txtvec.orig, retries=5, my.ignore.case=TRUE, my.max.distance=2){\n  txtvec <- txtvec.orig\n  for(i in 1:retries){\n    fuzMatch <- aregexec(pattern, txtvec, max.distance=my.max.distance, ignore.case=my.ignore.case)\n      # max.distance=0.1 default. fuzzy matching of the pattern.\n    duh <- regmatches(txtvec, fuzMatch, invert=FALSE) # BUT 241,248,... also matched relevant QOS parts!\n      # [For vector match data, if invert is FALSE, value should be a character vector with length the number of matched\n      # elements in m.]\n    if(length(unlist(duh)) == 0) break # else continue\n    stopifnot(length(unlist(duh)) > 0)\n    print(glimpse(unlist(duh)))\n    regmatches(txtvec, fuzMatch, invert=FALSE) <- \"\" # Erase matched part of strings.\n  }\n  # Now, confirm pattern has been completely dropped:\n fuzMatch <- aregexec(pattern, txtvec, max.distance=my.max.distance, ignore.case=my.ignore.case)\n  duh <- regmatches(txtvec, fuzMatch, invert=FALSE)\n  stopifnot(length(unlist(duh)) == 0)\n\n  return(txtvec)\n}\ndropMorePatterns <- function(txtvec.orig, patternVec){\n  txtvec <- txtvec.orig\n  for(p in patternVec){\n    txtvec <- dropPattern(p, txtvec)\n  }\n  return(txtvec)\n}\n",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Installing packages into ‘/home/nbuser/R’\n(as ‘lib’ is unspecified)\nWarning message:\n“package ‘grid’ is not available (for R version 3.5.3)”Warning message:\n“package ‘grid’ is a base package, and should not be updated”also installing the dependencies ‘vctrs’, ‘lifecycle’, ‘proxyC’, ‘dplyr’, ‘haven’, ‘hms’, ‘modelr’, ‘tidyr’\n\nWarning message in install.packages(packages):\n“installation of package ‘shiny’ had non-zero exit status”Warning message in install.packages(packages):\n“installation of package ‘tm’ had non-zero exit status”",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "forOCR <- TRUE\ncK <- 7 # 2 unacceptable to stmFit; ctmFit too warns.\n  # 65 Topics as per JEE-Main 2020 Syllabus. Was: 40 in CTM ref likely coz visualizability on computer display.\n  # 2 might not be a bad place to start; one can see the topic model evolve, viewing differences in topic-word beta etc.\n  # 2*subjects=2*3=6 topics might be the minimum acceptable, as that allows (Difficulty or) Ease to be categorized per\n  # Subject into {hard,notHard}. Next option would be Difficulty to be categorized into {hard,medium,easy}; so\n  # cK=3*3=9 topics.\n  # To allow for a topic that doesn't covary with subject, cK=6+1=7 topics might be another option; 7 is also\n  # believed to limit human comprehension :-).\n  # To choose cK, consider searchK() or [When initialization type is set to \"Spectral\" the user can specify K = 0].\n\ndate()\ncFooter.Resonance <- c(\"Resonance Eduventures Pvt\\\\. Ltd\\\\.\nCORPORATE OFFICE : CG Tower, A-46 & 52, IPIA, Near City Mall, Jnalawar Road, Kota \\\\(Raj.\\\\) - 324005\nTel\\\\. No\\\\. : 0744-3192222, 3012222, 3022222 \\\\| Toll Free : 1800 200 2244 \\\\| To Know more : sms RESO at 96677\nWebsite : www\\\\.resonance\\\\.ac\\\\.in \\\\| Email : contact@resonance\\\\.ac\\\\.in\nThis solution was download from Resonance JEE ADVANCED 2014 Solution portal Page \\\\| \"\n  # alt: \"Resonance Eduventures .* Solution portal Page |\" # within the same string\n  # alt: \"Resonance Eduventures .* contact@resonance\\\\.ac\\\\.in\" # within the same string\n)\ncFooter.FIITJEE <- c(\"FIITJEE Ltd\\\\., FIITJEE House, 29-A, Kalu Sarai, Sarvapriya Vihar, New Delhi -110016, Ph 46106000, \n\n26569493, Fax 26513942\nwebsite: www\\\\.fiitjee\\\\.com\\\\.\"\n)\ncExtraStop.old <- c(\"jee\",\"advanced\",\"ans\",\"solution\",\"sol\",\"page\",\"choices\",\"multiple\",\"section\",\n  \"kota\",\"road\",\"office\",\"ltd\",\"website\",\"www.resonance.ac.in\",\"www\",\"fax\",\"city\",\n  \"contact@resonance.ac.in\",\"email\",\"eduventures\",\"corporate\",\"download\",\"portal\",\"sms\",\n  \"fiitjee\",\"fiitjee.com\",\"kalu\",\"sarai\",\"sarvapriya\",\"delhi\"\n)\n  # \"resonence\",\"resonsence\",\"besonence\",\"resonsnce\",\"resonance\",\"correct\", and single-letter tokens, possibly\n  # inside a QOS, might be worthy retaining.\n  # u   f0b5   f0ad   f0bc   f0ae ... b c d\n  # email IDs, addresses ...\n  # Above tokens might have to be removed.\ngetEstEffectTopicwisePlot.srOtot3 <- function(stmFit, out){\n  par(ask=TRUE)\n  prepEff.subject.srOtot3 <- list()\n  result.plot.prepEff <- list()\n  for(ti in 1:k){\n    # 2020Mar14:\n    # Topics 2 (mostly C) more prevalent with higher notrOtot3.\n    # Topic 6 (mostly C with mix of PM) prevalence moves the other way, while Topic 5 (mostly M) prevalence gradually\n    # reduces with higher notrOtot3.\n    myvar <- \"rOtot3\"; mymethod=\"continuous\"\n    fmla <- as.formula(paste0(\"c(\", ti, \") ~ subject * s(rOtot3)\")) # b-spline transformed var through s(var)\n    prepEff.subject.srOtot3[[ti]] <- estimateEffect(fmla, stmFit, meta=out$meta, uncertainty=\"Global\")\n    result.plot.prepEff[[ti]] <- plot(prepEff.subject.srOtot3[[ti]], myvar, method=mymethod, verbose.labels=T)\n  }\n  return(prepEff.subject.srOtot3)\n}\n\n# library(LDAvis)\n# library(servr)\npar(ask=TRUE)\nprint(cYPtill) # ensure till latest.\n",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "[1] \"Thu Mar 19 04:41:18 2020\"",
            "text/latex": "'Thu Mar 19 04:41:18 2020'",
            "text/markdown": "'Thu Mar 19 04:41:18 2020'",
            "text/html": "'Thu Mar 19 04:41:18 2020'"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "[1] \"Y2018P2\"\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "fname.meta.relPath <- paste0(cWorkDir, \"/out-qaJEEadvanced-Occipital.csv\"); print(fname.meta.relPath)\nresponses <- responses.orig <- getJADdata(fname.meta2=fname.meta.relPath)\nstr(responses); summary(responses)",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[1] \"./out-qaJEEadvanced-Occipital.csv\"\n[1] \"./jads-ocr-tillY2018P2.rds\"\n[1] 684   1\n'data.frame':\t684 obs. of  1 variable:\n $ dat.rds.flat: chr  \"1. Two large vertical and parallel metal plates having a separation of 1 cm are connected to a DC voltage sourc\"| __truncated__ \"2. A mixture of 2 moles of helium gas (atomic mass = 4 amu), and 1 mole of argon gas (atomic mass = 40 amu)\\n. \"| __truncated__ \"3. A small block is connected to one end of a massless spring of un-stretched length 4.9 m. The other end of th\"| __truncated__ \"4. Three very large plates of same area are kept parallel and close to each other. They are considered as ideal\"| __truncated__ ...\nNULL\n'data.frame':\t684 obs. of  2 variables:\n $ subject: Factor w/ 3 levels \"C\",\"M\",\"P\": 3 3 3 3 3 3 3 3 3 3 ...\n $ YP     : Factor w/ 12 levels \"Y2012P1\",\"Y2012P2\",..: 1 1 1 1 1 1 1 1 1 1 ...\nNULL\n'data.frame':\t684 obs. of  3 variables:\n $ QOS    : chr  \"1. Two large vertical and parallel metal plates having a separation of 1 cm are connected to a DC voltage sourc\"| __truncated__ \"2. A mixture of 2 moles of helium gas (atomic mass = 4 amu), and 1 mole of argon gas (atomic mass = 40 amu)\\n. \"| __truncated__ \"3. A small block is connected to one end of a massless spring of un-stretched length 4.9 m. The other end of th\"| __truncated__ \"4. Three very large plates of same area are kept parallel and close to each other. They are considered as ideal\"| __truncated__ ...\n $ subject: Factor w/ 3 levels \"C\",\"M\",\"P\": 3 3 3 3 3 3 3 3 3 3 ...\n $ YP     : Factor w/ 12 levels \"Y2012P1\",\"Y2012P2\",..: 1 1 1 1 1 1 1 1 1 1 ...\nNULL\n'data.frame':\t677 obs. of  27 variables:\n $ unattempted                              : int  38510 42122 38242 78136 52714 17632 22879 36133 37834 29613 ...\n $ wrong                                    : int  51117 64996 69095 50125 29914 25057 77084 104174 110251 91112 ...\n $ correct                                  : int  56556 25284 30124 17372 13477 48285 55195 14851 7073 34433 ...\n $ partCorrect1m                            : int  8975 22756 17697 9525 27122 24786 NA NA NA NA ...\n $ partCorrect2m                            : int  0 0 0 0 31931 39398 NA NA NA NA ...\n $ partCorrect3m                            : int  0 0 0 0 0 0 NA NA NA NA ...\n $ subject                                  : Factor w/ 3 levels \"chemistry\",\"maths\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ paper                                    : int  1 1 1 1 1 1 1 1 1 1 ...\n $ year                                     : int  2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 ...\n $ qaNum                                    : int  1 2 3 4 5 6 7 8 9 10 ...\n $ qaType                                   : Factor w/ 7 levels \"Compr\",\"MultCorrAns\",..: 2 2 2 2 2 2 3 3 3 3 ...\n $ markScheme                               : int  -201234 -201234 -201234 -201234 -201234 -201234 3 3 3 3 ...\n $ right                                    : int  58800 30973 34548 19753 36223 74181 55195 14851 7073 34433 ...\n $ tot                                      : int  155158 155158 155158 155158 155158 155158 155158 155158 155158 155158 ...\n $ wOtot                                    : num  0.329 0.419 0.445 0.323 0.193 0.161 0.497 0.671 0.711 0.587 ...\n $ uOtot                                    : num  0.248 0.271 0.246 0.504 0.34 0.114 0.147 0.233 0.244 0.191 ...\n $ cOtot                                    : num  0.365 0.163 0.194 0.112 0.087 0.311 0.356 0.096 0.046 0.222 ...\n $ rOtot                                    : num  0.379 0.2 0.223 0.127 0.233 0.478 0.356 0.096 0.046 0.222 ...\n $ not.rOtot                                : num  0.621 0.8 0.777 0.873 0.767 0.522 0.644 0.904 0.954 0.778 ...\n $ tmpQOSjads.ocr.tillY2018P2               : int  577 578 579 580 581 582 583 584 585 586 ...\n $ jeeadvqaNum                              : int  1 2 3 4 5 6 7 8 9 10 ...\n $ jeeadvqaType                             : Factor w/ 7 levels \"Compr\",\"MultCorrAns\",..: 2 2 2 2 2 2 3 3 3 3 ...\n $ jeeadvmarkScheme                         : Factor w/ 5 levels \"mark-103\",\"mark-104\",..: 3 3 3 3 3 3 5 5 5 5 ...\n $ YP                                       : Factor w/ 12 levels \"Y2012P1\",\"Y2012P2\",..: 11 11 11 11 11 11 11 11 11 11 ...\n $ X2020Feb17tmpQOSjads.ocr.tillY2014P2     : int  NA NA NA NA NA NA NA NA NA NA ...\n $ X2020Feb19tmpQOSjads.ocr.tillY2014P2     : int  NA NA NA NA NA NA NA NA NA NA ...\n $ values2020Feb19tmpQOSjads.ocr.tillY2014P2: int  NA NA NA NA NA NA NA NA NA NA ...\nNULL\n'data.frame':\t677 obs. of  27 variables:\n $ unattempted                              : int  38510 42122 38242 78136 52714 17632 22879 36133 37834 29613 ...\n $ wrong                                    : int  51117 64996 69095 50125 29914 25057 77084 104174 110251 91112 ...\n $ correct                                  : int  56556 25284 30124 17372 13477 48285 55195 14851 7073 34433 ...\n $ partCorrect1m                            : int  8975 22756 17697 9525 27122 24786 NA NA NA NA ...\n $ partCorrect2m                            : int  0 0 0 0 31931 39398 NA NA NA NA ...\n $ partCorrect3m                            : int  0 0 0 0 0 0 NA NA NA NA ...\n $ subject                                  : Factor w/ 3 levels \"C\",\"M\",\"P\": 3 3 3 3 3 3 3 3 3 3 ...\n $ paper                                    : int  1 1 1 1 1 1 1 1 1 1 ...\n $ year                                     : int  2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 ...\n $ qaNum                                    : int  1 2 3 4 5 6 7 8 9 10 ...\n $ qaType                                   : Factor w/ 7 levels \"Compr\",\"MultCorrAns\",..: 2 2 2 2 2 2 3 3 3 3 ...\n $ markScheme                               : int  -201234 -201234 -201234 -201234 -201234 -201234 3 3 3 3 ...\n $ right                                    : int  58800 30973 34548 19753 36223 74181 55195 14851 7073 34433 ...\n $ tot                                      : int  155158 155158 155158 155158 155158 155158 155158 155158 155158 155158 ...\n $ wOtot                                    : num  0.329 0.419 0.445 0.323 0.193 0.161 0.497 0.671 0.711 0.587 ...\n $ uOtot                                    : num  0.248 0.271 0.246 0.504 0.34 0.114 0.147 0.233 0.244 0.191 ...\n $ cOtot                                    : num  0.365 0.163 0.194 0.112 0.087 0.311 0.356 0.096 0.046 0.222 ...\n $ rOtot                                    : num  0.379 0.2 0.223 0.127 0.233 0.478 0.356 0.096 0.046 0.222 ...\n $ not.rOtot                                : num  0.621 0.8 0.777 0.873 0.767 0.522 0.644 0.904 0.954 0.778 ...\n $ ocrqaNum                                 : int  577 578 579 580 581 582 583 584 585 586 ...\n $ jeeadvqaNum                              : int  1 2 3 4 5 6 7 8 9 10 ...\n $ jeeadvqaType                             : Factor w/ 7 levels \"Compr\",\"MultCorrAns\",..: 2 2 2 2 2 2 3 3 3 3 ...\n $ jeeadvmarkScheme                         : Factor w/ 5 levels \"mark-103\",\"mark-104\",..: 3 3 3 3 3 3 5 5 5 5 ...\n $ YP                                       : Factor w/ 12 levels \"Y2012P1\",\"Y2012P2\",..: 11 11 11 11 11 11 11 11 11 11 ...\n $ X2020Feb17tmpQOSjads.ocr.tillY2014P2     : int  NA NA NA NA NA NA NA NA NA NA ...\n $ X2020Feb19tmpQOSjads.ocr.tillY2014P2     : int  NA NA NA NA NA NA NA NA NA NA ...\n $ values2020Feb19tmpQOSjads.ocr.tillY2014P2: int  NA NA NA NA NA NA NA NA NA NA ...\nNULL\n'data.frame':\t677 obs. of  27 variables:\n $ unattempted                              : int  38510 42122 38242 78136 52714 17632 22879 36133 37834 29613 ...\n $ wrong                                    : int  51117 64996 69095 50125 29914 25057 77084 104174 110251 91112 ...\n $ correct                                  : int  56556 25284 30124 17372 13477 48285 55195 14851 7073 34433 ...\n $ partCorrect1m                            : int  8975 22756 17697 9525 27122 24786 NA NA NA NA ...\n $ partCorrect2m                            : int  0 0 0 0 31931 39398 NA NA NA NA ...\n $ partCorrect3m                            : int  0 0 0 0 0 0 NA NA NA NA ...\n $ subject                                  : Factor w/ 3 levels \"C\",\"M\",\"P\": 3 3 3 3 3 3 3 3 3 3 ...\n $ paper                                    : int  1 1 1 1 1 1 1 1 1 1 ...\n $ year                                     : int  2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 ...\n $ qaNum                                    : int  1 2 3 4 5 6 7 8 9 10 ...\n $ qaType                                   : Factor w/ 7 levels \"Compr\",\"MultCorrAns\",..: 2 2 2 2 2 2 3 3 3 3 ...\n $ markScheme                               : int  -201234 -201234 -201234 -201234 -201234 -201234 3 3 3 3 ...\n $ right                                    : int  58800 30973 34548 19753 36223 74181 55195 14851 7073 34433 ...\n $ tot                                      : int  155158 155158 155158 155158 155158 155158 155158 155158 155158 155158 ...\n $ wOtot                                    : num  0.329 0.419 0.445 0.323 0.193 0.161 0.497 0.671 0.711 0.587 ...\n $ uOtot                                    : num  0.248 0.271 0.246 0.504 0.34 0.114 0.147 0.233 0.244 0.191 ...\n $ cOtot                                    : num  0.365 0.163 0.194 0.112 0.087 0.311 0.356 0.096 0.046 0.222 ...\n $ rOtot                                    : num  0.379 0.2 0.223 0.127 0.233 0.478 0.356 0.096 0.046 0.222 ...\n $ not.rOtot                                : num  0.621 0.8 0.777 0.873 0.767 0.522 0.644 0.904 0.954 0.778 ...\n $ ocrqaNum                                 : int  577 578 579 580 581 582 583 584 585 586 ...\n $ jeeadvqaNum                              : int  1 2 3 4 5 6 7 8 9 10 ...\n $ jeeadvqaType                             : Factor w/ 7 levels \"Compr\",\"MultCorrAns\",..: 2 2 2 2 2 2 3 3 3 3 ...\n $ jeeadvmarkScheme                         : Factor w/ 5 levels \"mark-103\",\"mark-104\",..: 3 3 3 3 3 3 5 5 5 5 ...\n $ YP                                       : Factor w/ 12 levels \"Y2012P1\",\"Y2012P2\",..: 11 11 11 11 11 11 11 11 11 11 ...\n $ X2020Feb17tmpQOSjads.ocr.tillY2014P2     : int  NA NA NA NA NA NA NA NA NA NA ...\n $ X2020Feb19tmpQOSjads.ocr.tillY2014P2     : int  NA NA NA NA NA NA NA NA NA NA ...\n $ values2020Feb19tmpQOSjads.ocr.tillY2014P2: int  NA NA NA NA NA NA NA NA NA NA ...\nNULL\n    unattempted  wrong correct partCorrect1m partCorrect2m partCorrect3m\n568      287624 123522   68505            NA            NA            NA\n567      192150 184143  103358            NA            NA            NA\n564      265586 136325   77740            NA            NA            NA\n561      290084 111637   77930            NA            NA            NA\n560      176389 223035   80227            NA            NA            NA\n563      243553 183531   52567            NA            NA            NA\n    subject paper year qaNum      qaType markScheme  right    tot wOtot uOtot\n568       P     1 2012     9 SingCorrAns       -103  68505 479651 0.258 0.600\n567       P     1 2012     8 SingCorrAns       -103 103358 479651 0.384 0.401\n564       P     1 2012     5 SingCorrAns       -103  77740 479651 0.284 0.554\n561       P     1 2012     2 SingCorrAns       -103  77930 479651 0.233 0.605\n560       P     1 2012     1 SingCorrAns       -103  80227 479651 0.465 0.368\n563       P     1 2012     4 SingCorrAns       -103  52567 479651 0.383 0.508\n    cOtot rOtot not.rOtot ocrqaNum jeeadvqaNum jeeadvqaType jeeadvmarkScheme\n568 0.143 0.143     0.857        1           9  SingCorrAns         mark-103\n567 0.215 0.215     0.785        2           8  SingCorrAns         mark-103\n564 0.162 0.162     0.838        3           5  SingCorrAns         mark-103\n561 0.162 0.162     0.838        4           2  SingCorrAns         mark-103\n560 0.167 0.167     0.833        5           1  SingCorrAns         mark-103\n563 0.110 0.110     0.890        6           4  SingCorrAns         mark-103\n         YP X2020Feb17tmpQOSjads.ocr.tillY2014P2\n568 Y2012P1                                    1\n567 Y2012P1                                    2\n564 Y2012P1                                    3\n561 Y2012P1                                    4\n560 Y2012P1                                    5\n563 Y2012P1                                    6\n    X2020Feb19tmpQOSjads.ocr.tillY2014P2\n568                                    1\n567                                    2\n564                                    3\n561                                    4\n560                                    5\n563                                    6\n    values2020Feb19tmpQOSjads.ocr.tillY2014P2\n568                                         1\n567                                         2\n564                                         3\n561                                         4\n560                                         5\n563                                         6\n    unattempted  wrong correct partCorrect1m partCorrect2m partCorrect3m\n103       29312 103176   22670            NA            NA            NA\n104       30628 112130   12400            NA            NA            NA\n105       46680  65685   42793            NA            NA            NA\n106       24055  38322   92781            NA            NA            NA\n107       48100  34382   72676            NA            NA            NA\n108       41378  74729   39051            NA            NA            NA\n    subject paper year qaNum                qaType markScheme right    tot\n103       M     2 2018    13                NumAns          3 22670 155158\n104       M     2 2018    14                NumAns          3 12400 155158\n105       M     2 2018    15 TwoListMatchSingleAns       -103 42793 155158\n106       M     2 2018    16 TwoListMatchSingleAns       -103 92781 155158\n107       M     2 2018    17 TwoListMatchSingleAns       -103 72676 155158\n108       M     2 2018    18 TwoListMatchSingleAns       -103 39051 155158\n    wOtot uOtot cOtot rOtot not.rOtot ocrqaNum jeeadvqaNum\n103 0.665 0.189 0.146 0.146     0.854      679          13\n104 0.723 0.197 0.080 0.080     0.920      680          14\n105 0.423 0.301 0.276 0.276     0.724      681          15\n106 0.247 0.155 0.598 0.598     0.402      682          16\n107 0.222 0.310 0.468 0.468     0.532      683          17\n108 0.482 0.267 0.252 0.252     0.748      684          18\n             jeeadvqaType jeeadvmarkScheme      YP\n103                NumAns         mark+003 Y2018P2\n104                NumAns         mark+003 Y2018P2\n105 TwoListMatchSingleAns         mark-103 Y2018P2\n106 TwoListMatchSingleAns         mark-103 Y2018P2\n107 TwoListMatchSingleAns         mark-103 Y2018P2\n108 TwoListMatchSingleAns         mark-103 Y2018P2\n    X2020Feb17tmpQOSjads.ocr.tillY2014P2 X2020Feb19tmpQOSjads.ocr.tillY2014P2\n103                                   NA                                   NA\n104                                   NA                                   NA\n105                                   NA                                   NA\n106                                   NA                                   NA\n107                                   NA                                   NA\n108                                   NA                                   NA\n    values2020Feb19tmpQOSjads.ocr.tillY2014P2\n103                                        NA\n104                                        NA\n105                                        NA\n106                                        NA\n107                                        NA\n108                                        NA\n[1] 677\n[1] 7\n[1]  82 120 496 509 539 569 571\n'data.frame':\t677 obs. of  30 variables:\n $ QOS                                      : chr  \"1. Two large vertical and parallel metal plates having a separation of 1 cm are connected to a DC voltage sourc\"| __truncated__ \"2. A mixture of 2 moles of helium gas (atomic mass = 4 amu), and 1 mole of argon gas (atomic mass = 40 amu)\\n. \"| __truncated__ \"3. A small block is connected to one end of a massless spring of un-stretched length 4.9 m. The other end of th\"| __truncated__ \"4. Three very large plates of same area are kept parallel and close to each other. They are considered as ideal\"| __truncated__ ...\n $ subject                                  : Factor w/ 3 levels \"C\",\"M\",\"P\": 3 3 3 3 3 3 3 3 3 3 ...\n $ YP                                       : Factor w/ 12 levels \"Y2012P1\",\"Y2012P2\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ unattempted                              : int  287624 192150 265586 290084 176389 243553 137160 208443 166651 70991 ...\n $ wrong                                    : int  123522 184143 136325 111637 223035 183531 193538 193386 230283 187819 ...\n $ correct                                  : int  68505 103358 77740 77930 80227 52567 148953 77822 82717 220841 ...\n $ partCorrect1m                            : int  NA NA NA NA NA NA NA NA NA NA ...\n $ partCorrect2m                            : int  NA NA NA NA NA NA NA NA NA NA ...\n $ partCorrect3m                            : int  NA NA NA NA NA NA NA NA NA NA ...\n $ subject                                  : Factor w/ 3 levels \"C\",\"M\",\"P\": 3 3 3 3 3 3 3 3 3 3 ...\n $ paper                                    : int  1 1 1 1 1 1 1 1 1 1 ...\n $ year                                     : int  2012 2012 2012 2012 2012 2012 2012 2012 2012 2012 ...\n $ qaNum                                    : int  9 8 5 2 1 4 3 10 7 6 ...\n $ qaType                                   : Factor w/ 7 levels \"Compr\",\"MultCorrAns\",..: 5 5 5 5 5 5 5 5 5 5 ...\n $ markScheme                               : int  -103 -103 -103 -103 -103 -103 -103 -103 -103 -103 ...\n $ right                                    : int  68505 103358 77740 77930 80227 52567 148953 77822 82717 220841 ...\n $ tot                                      : int  479651 479651 479651 479651 479651 479651 479651 479651 479651 479651 ...\n $ wOtot                                    : num  0.258 0.384 0.284 0.233 0.465 0.383 0.403 0.403 0.48 0.392 ...\n $ uOtot                                    : num  0.6 0.401 0.554 0.605 0.368 0.508 0.286 0.435 0.347 0.148 ...\n $ cOtot                                    : num  0.143 0.215 0.162 0.162 0.167 0.11 0.311 0.162 0.172 0.46 ...\n $ rOtot                                    : num  0.143 0.215 0.162 0.162 0.167 0.11 0.311 0.162 0.172 0.46 ...\n $ not.rOtot                                : num  0.857 0.785 0.838 0.838 0.833 0.89 0.689 0.838 0.828 0.54 ...\n $ ocrqaNum                                 : int  1 2 3 4 5 6 7 8 9 10 ...\n $ jeeadvqaNum                              : int  9 8 5 2 1 4 3 10 7 6 ...\n $ jeeadvqaType                             : Factor w/ 7 levels \"Compr\",\"MultCorrAns\",..: 5 5 5 5 5 5 5 5 5 5 ...\n $ jeeadvmarkScheme                         : Factor w/ 5 levels \"mark-103\",\"mark-104\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ YP                                       : Factor w/ 12 levels \"Y2012P1\",\"Y2012P2\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ X2020Feb17tmpQOSjads.ocr.tillY2014P2     : int  1 2 3 4 5 6 7 8 9 10 ...\n $ X2020Feb19tmpQOSjads.ocr.tillY2014P2     : int  1 2 3 4 5 6 7 8 9 10 ...\n $ values2020Feb19tmpQOSjads.ocr.tillY2014P2: int  1 2 3 4 5 6 7 8 9 10 ...\nNULL\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "'data.frame':\t677 obs. of  27 variables:\n $ QOS             : chr  \"1. Two large vertical and parallel metal plates having a separation of 1 cm are connected to a DC voltage sourc\"| __truncated__ \"2. A mixture of 2 moles of helium gas (atomic mass = 4 amu), and 1 mole of argon gas (atomic mass = 40 amu)\\n. \"| __truncated__ \"3. A small block is connected to one end of a massless spring of un-stretched length 4.9 m. The other end of th\"| __truncated__ \"4. Three very large plates of same area are kept parallel and close to each other. They are considered as ideal\"| __truncated__ ...\n $ subject         : Factor w/ 3 levels \"C\",\"M\",\"P\": 3 3 3 3 3 3 3 3 3 3 ...\n $ YP              : Factor w/ 12 levels \"Y2012P1\",\"Y2012P2\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ unattempted     : int  287624 192150 265586 290084 176389 243553 137160 208443 166651 70991 ...\n $ wrong           : int  123522 184143 136325 111637 223035 183531 193538 193386 230283 187819 ...\n $ correct         : int  68505 103358 77740 77930 80227 52567 148953 77822 82717 220841 ...\n $ partCorrect1m   : int  NA NA NA NA NA NA NA NA NA NA ...\n $ partCorrect2m   : int  NA NA NA NA NA NA NA NA NA NA ...\n $ partCorrect3m   : int  NA NA NA NA NA NA NA NA NA NA ...\n $ paper           : int  1 1 1 1 1 1 1 1 1 1 ...\n $ year            : int  2012 2012 2012 2012 2012 2012 2012 2012 2012 2012 ...\n $ right           : int  68505 103358 77740 77930 80227 52567 148953 77822 82717 220841 ...\n $ tot             : int  479651 479651 479651 479651 479651 479651 479651 479651 479651 479651 ...\n $ wOtot           : num  0.258 0.384 0.284 0.233 0.465 0.383 0.403 0.403 0.48 0.392 ...\n $ uOtot           : num  0.6 0.401 0.554 0.605 0.368 0.508 0.286 0.435 0.347 0.148 ...\n $ cOtot           : num  0.143 0.215 0.162 0.162 0.167 0.11 0.311 0.162 0.172 0.46 ...\n $ rOtot           : num  0.143 0.215 0.162 0.162 0.167 0.11 0.311 0.162 0.172 0.46 ...\n $ not.rOtot       : num  0.857 0.785 0.838 0.838 0.833 0.89 0.689 0.838 0.828 0.54 ...\n $ ocrqaNum        : int  1 2 3 4 5 6 7 8 9 10 ...\n $ jeeadvqaNum     : int  9 8 5 2 1 4 3 10 7 6 ...\n $ jeeadvqaType    : Factor w/ 7 levels \"Compr\",\"MultCorrAns\",..: 5 5 5 5 5 5 5 5 5 5 ...\n $ jeeadvmarkScheme: Factor w/ 5 levels \"mark-103\",\"mark-104\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ uOtot3          : num  600 401 554 605 368 508 286 435 347 148 ...\n $ rOtot3          : num  143 215 162 162 167 110 311 162 172 460 ...\n $ notrOtot3       : num  857 785 838 838 833 890 689 838 828 540 ...\n $ rOtotGrp        : Factor w/ 2 levels \"above25tile\",..: 1 1 1 1 1 2 1 1 1 1 ...\n $ idYPSQ          : Factor w/ 677 levels \"Y2012P1C21\",\"Y2012P1C22\",..: 60 59 56 52 41 55 54 42 58 57 ...\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "     QOS            subject       YP       unattempted         wrong       \n Length:677         C:226   Y2012P1: 60   Min.   :  1278   Min.   :     0  \n Class :character   M:224   Y2013P1: 60   1st Qu.: 16449   1st Qu.: 40932  \n Mode  :character   P:227   Y2013P2: 60   Median : 41378   Median : 62529  \n                            Y2014P1: 60   Mean   : 54660   Mean   : 94494  \n                            Y2014P2: 60   3rd Qu.: 70842   3rd Qu.:103343  \n                            Y2012P2: 58   Max.   :309270   Max.   :427054  \n                            (Other):319                                    \n    correct       partCorrect1m   partCorrect2m   partCorrect3m    \n Min.   :   416   Min.   :    0   Min.   :    0   Min.   :    0.0  \n 1st Qu.: 17476   1st Qu.:11724   1st Qu.:    0   1st Qu.:    0.0  \n Median : 35970   Median :19399   Median :    0   Median :    0.0  \n Mean   : 43272   Mean   :19838   Mean   : 9522   Mean   :  175.5  \n 3rd Qu.: 57657   3rd Qu.:27301   3rd Qu.:17604   3rd Qu.:    0.0  \n Max.   :238246   Max.   :48793   Max.   :68870   Max.   :13645.0  \n                  NA's   :549     NA's   :554     NA's   :554      \n     paper            year          right             tot        \n Min.   :1.000   Min.   :2012   Min.   :   416   Min.   :115971  \n 1st Qu.:1.000   1st Qu.:2013   1st Qu.: 21046   1st Qu.:119580  \n Median :1.000   Median :2014   Median : 37286   Median :147678  \n Mean   :1.498   Mean   :2015   Mean   : 45098   Mean   :197938  \n 3rd Qu.:2.000   3rd Qu.:2017   3rd Qu.: 58800   3rd Qu.:159540  \n Max.   :2.000   Max.   :2018   Max.   :238246   Max.   :479651  \n                                                                 \n     wOtot            uOtot            cOtot            rOtot       \n Min.   :0.0000   Min.   :0.0110   Min.   :0.0030   Min.   :0.0030  \n 1st Qu.:0.2900   1st Qu.:0.0990   1st Qu.:0.1120   1st Qu.:0.1290  \n Median :0.4110   Median :0.2520   Median :0.2010   Median :0.2150  \n Mean   :0.4495   Mean   :0.2785   Mean   :0.2362   Mean   :0.2481  \n 3rd Qu.:0.6170   3rd Qu.:0.4280   3rd Qu.:0.3200   3rd Qu.:0.3290  \n Max.   :0.9070   Max.   :0.8000   Max.   :0.8620   Max.   :0.8620  \n                                                                    \n   not.rOtot         ocrqaNum      jeeadvqaNum                   jeeadvqaType\n Min.   :0.1380   Min.   :  1.0   Min.   : 1.00   Compr                : 18  \n 1st Qu.:0.6710   1st Qu.:172.0   1st Qu.:11.00   MultCorrAns          :210  \n Median :0.7850   Median :341.0   Median :24.00   NumAns               : 48  \n Mean   :0.7519   Mean   :341.8   Mean   :26.13   ParaSingleAns        : 83  \n 3rd Qu.:0.8710   3rd Qu.:512.0   3rd Qu.:41.00   SingCorrAns          :175  \n Max.   :0.9970   Max.   :684.0   Max.   :60.00   SingDigitInteger     : 89  \n                                                  TwoListMatchSingleAns: 54  \n    jeeadvmarkScheme     uOtot3          rOtot3        notrOtot3    \n mark-103   :287     Min.   : 11.0   Min.   :  3.0   Min.   :138.0  \n mark-104   : 30     1st Qu.: 99.0   1st Qu.:129.0   1st Qu.:671.0  \n mark-201234:123     Median :252.0   Median :215.0   Median :785.0  \n mark+002   : 30     Mean   :278.5   Mean   :248.1   Mean   :751.9  \n mark+003   :207     3rd Qu.:428.0   3rd Qu.:329.0   3rd Qu.:871.0  \n                     Max.   :800.0   Max.   :862.0   Max.   :997.0  \n                                                                    \n        rOtotGrp          idYPSQ   \n above25tile:506   Y2012P1C21:  1  \n below25tile:171   Y2012P1C22:  1  \n                   Y2012P1C23:  1  \n                   Y2012P1C24:  1  \n                   Y2012P1C25:  1  \n                   Y2012P1C26:  1  \n                   (Other)   :671  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "  # Done: Later, merge with outJADinsight.csv too; then use rOtot possibly as binary factor as Topical-Content covariate.\n# Fixed:\n# idYPQ: Factor w/ 605 levels!! YP:: Y2012P2: 58!! mark-201235: 2!! Seem suspect! Was jeeadvqaNum correctly suffixed as Q?\n\nresponses.covars <- c(\"subject\", \"YP\", \"jeeadvqaType\", \"jeeadvmarkScheme\", \"uOtot3\", \"rOtot3\", \"notrOtot3\",\n  \"rOtotGrp\", \"idYPSQ\", \"right\", \"tot\") # Was: \"idYPQ\". 2020Mar15: included c(\"right\", \"tot\").\n  # column names of covariates or docvars.\n# duh <- dropPattern(cFooter.FIITJEE, txtvec.noR)\n# duh2 <- dropPattern(cFooter.FIITJEE, duh)\n# duh7 <- dropMorePatterns(responses[,1], patternVec=c(cFooter.Resonance, cFooter.FIITJEE))\n# responses[,1] <- duh\nresponses[,1] <- dropMorePatterns(responses[,1], patternVec=c(cFooter.Resonance, cFooter.FIITJEE))\nresponses <- responses[which(! is.na(responses$rOtot3)), c(\"QOS\", responses.covars)]; summary(responses)\n",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "Error in glimpse(unlist(duh)): could not find function \"glimpse\"\n",
          "traceback": [
            "Error in glimpse(unlist(duh)): could not find function \"glimpse\"\nTraceback:\n",
            "1. dropMorePatterns(responses[, 1], patternVec = c(cFooter.Resonance, \n .     cFooter.FIITJEE))",
            "2. dropPattern(p, txtvec)   # at line 603 of file <text>",
            "3. print(glimpse(unlist(duh)))   # at line 590 of file <text>"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "Error in library(quanteda): there is no package called ‘quanteda’\n",
          "traceback": [
            "Error in library(quanteda): there is no package called ‘quanteda’\nTraceback:\n",
            "1. library(quanteda)",
            "2. stop(txt, domain = NA)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "r",
      "display_name": "R",
      "language": "R"
    },
    "language_info": {
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.5.3",
      "file_extension": ".r",
      "codemirror_mode": "r"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}